# **PRD: Hodei Artifacts**

## **1\. Visi√≥n General**

Hodei Artifacts es un sistema de repositorio de artefactos de alto rendimiento construido en Rust, dise√±ado como una alternativa moderna a soluciones como Nexus, Artifactory y Archiva. La soluci√≥n implementa arquitecturas avanzadas (Hexagonal, Vertical Slice) con un enfoque **Contract First** y ofrece soporte nativo para almacenamiento compatible con S3, utilizando MinIO como implementaci√≥n de referencia.

## **2\. Objetivos del Sistema**

* **Alto Rendimiento:** Aprovechar las capacidades de concurrencia y la eficiencia de memoria de Rust para ofrecer tiempos de respuesta inferiores a 50ms en operaciones cr√≠ticas de lectura/escritura de metadatos.
* **Escalabilidad Horizontal:** Dise√±ado desde su concepci√≥n para despliegues nativos en la nube sobre Kubernetes, con capacidad de autoescalado basado en m√©tricas de rendimiento (CPU, memoria, peticiones por segundo).
* **Soporte Multi-formato:** Brindar soporte nativo y de primera clase para los ecosistemas de artefactos m√°s comunes, incluyendo **Maven, npm, Docker, NuGet y PyPI**, en un √∫nico sistema unificado.
* **Almacenamiento S3-Compatible:** Implementar una capa de almacenamiento flexible a trav√©s de un puerto (StorageDriver) con una implementaci√≥n nativa de referencia para **MinIO**, garantizando la compatibilidad con cualquier proveedor de almacenamiento de objetos compatible con S3.
* **Arquitecturas Modernas:** El dise√±o se basa estrictamente en los principios de **Arquitectura Hexagonal** para el desacoplamiento y **Vertical Slice** para la organizaci√≥n del c√≥digo por funcionalidad, maximizando la cohesi√≥n y minimizando el acoplamiento.
* **Desarrollo Contract First:** El ciclo de vida del desarrollo estar√° guiado por contratos de API definidos en **OpenAPI**. Esto incluye la generaci√≥n autom√°tica de c√≥digo para clientes y stubs de servidor, asegurando la consistencia y permitiendo el desarrollo en paralelo.

## **3\. Arquitectura T√©cnica: Principios Fundamentales**

La arquitectura de Hodei Artifacts se fundamenta en el patr√≥n de **Arquitectura Hexagonal (Puertos y Adaptadores)** para garantizar un n√∫cleo de negocio aislado y flexible.

### **3.1. Puertos Principales**

Los siguientes puertos (definidos como traits en Rust) constituyen los contratos clave que el n√∫cleo de la aplicaci√≥n utiliza para interactuar con la infraestructura externa:

* **ArtifactRepository:** Define las operaciones para la gesti√≥n de metadatos de artefactos (crear, leer, actualizar, eliminar, buscar).
* **StorageDriver:** Abstrae el almacenamiento f√≠sico de los binarios de los artefactos (subir, descargar, eliminar).
* **UserRepository:** Define la gesti√≥n de usuarios, roles y permisos.
* **EventPublisher:** Proporciona una interfaz para la publicaci√≥n de eventos de dominio a un bus de mensajer√≠a.
* **PolicyRepository:** Abstrae el almacenamiento y la consulta de pol√≠ticas de autorizaci√≥n para el motor ABAC.

## **4\. Usuarios y Roles Objetivo (Personas)**

* **Desarrollador de Software:** Interact√∫a con Hodei Artifacts para publicar y recuperar artefactos de desarrollo y dependencias. Requiere un acceso r√°pido y fiable, as√≠ como una documentaci√≥n de API clara.
* **Sistema de CI/CD (Actor Automatizado):** El usuario principal de Hodei Artifacts. Env√≠a artefactos de compilaci√≥n, extrae dependencias para las etapas posteriores del pipeline y activa escaneos de seguridad automatizados. Requiere puntos finales de API robustos y de alto rendimiento, as√≠ como mecanismos de autenticaci√≥n fiables (por ejemplo, tokens OIDC).
* **Auditor de Seguridad / Ingeniero de DevSecOps:** Interact√∫a con Hodei Artifacts para auditar artefactos, revisar SBOMs, verificar firmas y aplicar pol√≠ticas de control de acceso. Requiere un registro completo, pistas de eventos auditables y controles de seguridad s√≥lidos.
* **Administrador de Sistemas / SRE:** Responsable del despliegue, mantenimiento y monitorizaci√≥n de la plataforma Hodei Artifacts. Requiere gu√≠as de despliegue claras (Helm charts), una observabilidad robusta (m√©tricas, registros, trazas) y procedimientos operativos bien definidos.

## **5\. Principios Arquitect√≥nicos Rectores**

Esta secci√≥n codifica las decisiones arquitect√≥nicas fundamentales que gobernar√°n el dise√±o y la implementaci√≥n del sistema, garantizando la coherencia, la calidad y la alineaci√≥n con los objetivos a largo plazo del proyecto.

### **5.1. El Modelo Arquitect√≥nico Unificado: Una S√≠ntesis de Patrones**

La arquitectura de Hodei Artifacts es una s√≠ntesis deliberada de tres patrones complementarios: Arquitectura de Slice Vertical (VSA), Arquitectura Hexagonal y Arquitectura Orientada a Eventos (EDA). Este enfoque h√≠brido est√° dise√±ado para maximizar la agilidad, la mantenibilidad y la escalabilidad.

* **VSA** proporciona la organizaci√≥n a nivel macro, estructurando el c√≥digo base en torno a las capacidades de negocio en lugar de las capas t√©cnicas. Esto apoya directamente el desarrollo √°gil al permitir que los equipos trabajen en funcionalidades en paralelo con una fricci√≥n m√≠nima.1
* La **Arquitectura Hexagonal** proporciona la estructura a nivel micro *dentro* de cada slice vertical. A√≠sla la l√≥gica de negocio central (el "dominio") de las preocupaciones externas como bases de datos, intermediarios de mensajes o frameworks web. Esto se logra a trav√©s de "puertos" (interfaces que definen interacciones) y "adaptadores" (implementaciones concretas para tecnolog√≠as espec√≠ficas).4 Este principio no es negociable, ya que garantiza la capacidad de prueba y la flexibilidad tecnol√≥gica.
* **EDA** sirve como el tejido conectivo entre los slices, permitiendo una comunicaci√≥n as√≠ncrona y d√©bilmente acoplada. Esto mejora la resiliencia del sistema, ya que el fallo de un slice no se propaga en cascada y derriba a otros, y soporta el procesamiento escalable y en paralelo de tareas.7

La combinaci√≥n de estos patrones da como resultado un "monolito modular escalable" que est√° preparado para una futura evoluci√≥n hacia microservicios. Cada slice vertical, con su n√∫cleo hexagonal y su comunicaci√≥n basada en eventos, es un candidato natural para ser extra√≠do a un servicio separado y desplegable de forma independiente. Esta arquitectura mitiga el alto coste inicial y la complejidad de un enfoque de microservicios completo, al tiempo que conserva la opci√≥n de una futura descomposici√≥n sin una reescritura importante. El sistema est√° estructurado internamente como un conjunto de microservicios pero se despliega como una √∫nica unidad, proporcionando los beneficios de desarrollo de la modularidad sin la complejidad operativa inmediata de la distribuci√≥n. Cuando un slice espec√≠fico requiera escalado o despliegue independiente, podr√° ser extra√≠do con cambios m√≠nimos en el c√≥digo, ya que sus l√≠mites y patrones de comunicaci√≥n ya est√°n definidos. Esta es una decisi√≥n estrat√©gica que equilibra la velocidad a corto plazo con la flexibilidad arquitect√≥nica a largo plazo.3

### **5.2. Vertical Slices como L√≠mites de Funcionalidad**

Cada capacidad de negocio o caso de uso distinto se implementar√° como un slice vertical autocontenido. Un slice abarca todo el c√≥digo necesario para satisfacer una solicitud, desde la definici√≥n del punto final de la API hasta la l√≥gica de acceso a los datos.11

El principio fundamental es **maximizar la cohesi√≥n dentro de un slice y minimizar el acoplamiento entre slices**.2 Los cambios en una funcionalidad deben localizarse en su slice correspondiente, reduciendo dr√°sticamente el riesgo de efectos secundarios no deseados y simplificando el mantenimiento.3

El intercambio de l√≥gica entre slices debe minimizarse. Cualquier l√≥gica compartida debe ser cuidadosamente evaluada y ubicada en una biblioteca compartida dedicada y bien definida, entendiendo que esto introduce un punto de acoplamiento que debe ser gestionado.3

### **5.3. El N√∫cleo Hexagonal dentro de los Slices**

Dentro de cada slice vertical, la l√≥gica de negocio central (entidades de dominio, servicios y casos de uso) debe ser completamente independiente de cualquier framework o tecnolog√≠a de infraestructura espec√≠fica.4

Las dependencias siempre deben apuntar hacia adentro: la capa de infraestructura (por ejemplo, un adaptador de repositorio de MongoDB) depende de la capa de dominio (por ejemplo, un puerto/interfaz ArtifactRepository), nunca al rev√©s. Esta es la esencia del Principio de Inversi√≥n de Dependencias.4

Esta estructura hace que la l√≥gica central sea eminentemente comprobable de forma aislada, utilizando adaptadores simulados para dependencias como bases de datos o APIs externas, lo que mejora significativamente la velocidad y fiabilidad de las pruebas.5

### **5.4. As√≠ncrono por Defecto, S√≠ncrono cuando sea Necesario**

La comunicaci√≥n entre slices ser√° principalmente as√≠ncrona, mediada por un bus de eventos central (Kafka). Cuando un slice completa una acci√≥n (por ejemplo, ArtefactoIngestado), publicar√° un evento. Otros slices interesados se suscribir√°n a este evento y reaccionar√°n en consecuencia (por ejemplo, IniciarEscaneoVulnerabilidades, ActualizarIndiceBusqueda).7

La comunicaci√≥n s√≠ncrona a trav√©s de APIs REST se reserva para las interacciones iniciadas por clientes externos (usuarios, sistemas de CI/CD). Estas solicitudes son manejadas por un "adaptador de entrada" dedicado dentro de un slice vertical espec√≠fico.5

### **5.5. Mandato de Contract-First para todas las APIs S√≠ncronas**

Todas las APIs s√≠ncronas (RESTful) deben definirse utilizando la especificaci√≥n OpenAPI 3.x *antes* de que se escriba cualquier c√≥digo de implementaci√≥n. Este contrato sirve como la √∫nica fuente de verdad para el comportamiento de la API.16

El contrato OpenAPI se almacenar√° en el repositorio de c√≥digo fuente y se utilizar√° para generar autom√°ticamente bibliotecas cliente de API, stubs de servidor y documentaci√≥n. Esta pr√°ctica permite el desarrollo en paralelo, ya que los equipos de frontend/cliente pueden trabajar con servidores simulados generados a partir del contrato mientras la implementaci√≥n del backend est√° en curso.16

Se aplicar√° una estricta gu√≠a de estilo de API para garantizar la coherencia en todos los puntos finales en t√©rminos de convenciones de nomenclatura, manejo de errores y c√≥digos de estado.16

## **6\. Requisitos Funcionales (Funcionalidades como Vertical Slices)**

Cada subsecci√≥n aqu√≠ representa un slice vertical autocontenido. La implementaci√≥n de cada slice se adherir√° a los principios Hexagonales y Orientados a Eventos descritos en la Secci√≥n II. Las definiciones de API seguir√°n el mandato de Contract-First.

### **6.1. Slice: Ingesta y Almacenamiento de Artefactos**

* **Historia de Usuario:** Como Sistema de CI/CD, quiero subir un artefacto de software con sus metadatos asociados para que pueda ser almacenado de forma segura y estar disponible para que otros sistemas lo consuman.
* **Requisitos Funcionales:**
  * El sistema debe aceptar la subida de artefactos a trav√©s de una solicitud HTTP POST multipart/form-data.
  * El sistema debe soportar artefactos de hasta 10 GB de tama√±o.
  * El sistema debe extraer metadatos clave de la solicitud (por ejemplo, nombre del artefacto, versi√≥n, ruta del repositorio, tipo de contenido).
  * El sistema debe calcular un hash criptogr√°fico (SHA-256) del contenido del artefacto al recibirlo para garantizar la integridad.
  * Los datos binarios del artefacto deben almacenarse en una soluci√≥n de almacenamiento de objetos duradera y compatible con S3.20
  * Los metadatos del artefacto y una referencia a su ubicaci√≥n de almacenamiento deben persistir en la base de datos de metadatos (MongoDB).22
  * Tras una ingesta exitosa, el sistema debe publicar un evento ArtifactUploaded en el bus de eventos.9
* **Punto Final de API (Contract-First):**
  * POST /v1/repositories/{repo\_path}/artifacts
  * Cuerpo de la Solicitud: multipart/form-data conteniendo el archivo del artefacto y una parte JSON de metadatos.
  * Respuesta: 202 Accepted con una cabecera Location apuntando al recurso del artefacto reci√©n creado.

### **6.2. Slice: Recuperaci√≥n y Versionado de Artefactos**

* **Historia de Usuario:** Como Desarrollador, quiero descargar una versi√≥n espec√≠fica de un artefacto de software de un repositorio para poder usarlo como dependencia en mi proyecto.
* **Requisitos Funcionales:**
  * El sistema debe proporcionar un enlace de descarga seguro para cualquier artefacto almacenado a trav√©s de una solicitud HTTP GET.
  * El sistema debe soportar la recuperaci√≥n de artefactos por su versi√≥n exacta (por ejemplo, 1.2.3) o por una etiqueta de versi√≥n (por ejemplo, latest).
  * El acceso a los artefactos debe estar controlado por las reglas de autorizaci√≥n definidas en el slice "Autenticaci√≥n y Autorizaci√≥n".
  * El sistema debe registrar todos los intentos de descarga de artefactos, incluyendo la identidad del usuario y la marca de tiempo.
* **Punto Final de API (Contract-First):**
  * GET /v1/repositories/{repo\_path}/artifacts/{artifact\_name}/{version}
  * Respuesta: 200 OK con el binario del artefacto en el cuerpo de la respuesta, o 302 Found redirigiendo a una URL de S3 pre-firmada.

### **6.3. Slice: B√∫squeda e Indexaci√≥n de Metadatos (Consumidor de Eventos)**

* **Historia de Usuario:** Como Ingeniero de DevSecOps, quiero buscar artefactos bas√°ndome en sus metadatos (por ejemplo, nombre, versi√≥n, hash, etiquetas personalizadas) para poder localizar r√°pidamente activos para auditor√≠a o an√°lisis.
* **Requisitos Funcionales:**
  * Este slice actuar√° como consumidor del evento ArtifactUploaded.
  * Al recibir un evento ArtifactUploaded, este slice actualizar√° un √≠ndice de b√∫squeda dedicado en MongoDB con los metadatos del artefacto.24
  * El sistema debe proporcionar una API de b√∫squeda que permita consultar artefactos por varios campos de metadatos.
  * La API de b√∫squeda debe soportar paginaci√≥n, ordenaci√≥n y filtrado.
* **Punto Final de API (Contract-First):**
  * GET /v1/search/artifacts?q={query\_string}\&page={num}\&sort={field}
  * Respuesta: 200 OK con un array JSON de metadatos de artefactos coincidentes.

### **6.4. Slice: Autenticaci√≥n y Autorizaci√≥n**

* **Historia de Usuario:** Como Administrador de Sistemas, quiero definir pol√≠ticas de acceso granular para los repositorios para poder controlar qu√© usuarios y sistemas pueden leer o escribir en ellos.
* **Requisitos Funcionales:**
  * El sistema debe asegurar todos los puntos finales de la API. Las solicitudes no autenticadas deben ser rechazadas con un estado 401 Unauthorized.
  * La autenticaci√≥n se basar√° en JSON Web Tokens (JWTs) emitidos por un proveedor de identidad externo (por ejemplo, Zitadel, como se menciona en 12).
  * La autorizaci√≥n se implementar√° utilizando un modelo de **Control de Acceso Basado en Atributos (ABAC)**. Esto proporciona m√°s flexibilidad que el tradicional Control de Acceso Basado en Roles (RBAC).26
  * Las pol√≠ticas se definir√°n en funci√≥n de los atributos del sujeto (por ejemplo, grupo del usuario, nombre de la cuenta de servicio), el recurso (por ejemplo, nivel de sensibilidad del repositorio) y la acci√≥n (por ejemplo, read, write, delete).26
  * El motor de pol√≠ticas se implementar√° utilizando el crate de Rust **cedar-policy**. Cedar es un lenguaje de pol√≠ticas de c√≥digo abierto dise√±ado para definir permisos detallados como pol√≠ticas que describen qui√©n debe tener acceso a qu√©.29 Este enfoque permite desacoplar la l√≥gica de autorizaci√≥n del c√≥digo de la aplicaci√≥n y soporta de forma nativa modelos comunes como el Control de Acceso Basado en Roles (RBAC) y el Control de Acceso Basado en Atributos (ABAC), aline√°ndose perfectamente con los requisitos del sistema.31 La integraci√≥n se realizar√° directamente en la aplicaci√≥n utilizando el motor de evaluaci√≥n de Cedar proporcionado por el crate.29
* **Puntos Finales de API (Contract-First):**
  * POST /v1/auth/policies
  * GET /v1/auth/policies/{policy\_id}

La elecci√≥n de ABAC sobre RBAC es una decisi√≥n cr√≠tica que apoya directamente el objetivo del sistema de ser una pieza fundamental de una cadena de suministro *segura*. Mientras que RBAC es m√°s simple, a menudo es demasiado grueso para los permisos complejos requeridos en un SDLC moderno (por ejemplo, "Permitir que los trabajos de CI de la rama 'production' env√≠en al repositorio 'release', pero solo entre las 2 AM y las 4 AM"). ABAC proporciona esta capacidad de autorizaci√≥n contextual y din√°mica necesaria. Este modelo es m√°s flexible y potente, ya que define pol√≠ticas basadas en atributos del usuario, recurso, acci√≥n y entorno, algo imposible de modelar limpiamente con RBAC.26 La existencia de bibliotecas maduras de Rust como

cedar-policy 29 hace que esta elecci√≥n sea t√©cnicamente factible, representando una inversi√≥n inicial m√°s compleja que ofrece dividendos significativos en seguridad y flexibilidad a largo plazo.

## **7\. Especificaci√≥n de API y Cat√°logo de Eventos**

### **7.1. Visi√≥n General de la API REST (OpenAPI)**

Se crear√° y mantendr√° un archivo openapi.yaml fundamental en la ra√≠z del repositorio del proyecto. Este archivo servir√° como el contrato maestro para todas las APIs s√≠ncronas.

Inicialmente, definir√° los puntos finales, esquemas y esquemas de seguridad para los slices detallados en la Secci√≥n III.

Se integrar√°n herramientas en el pipeline de CI/CD para validar el contrato y generar stubs de servidor y documentaci√≥n a partir de este archivo, reforzando el enfoque Contract-First.17

### **7.2. Definiciones de Eventos**

La comunicaci√≥n as√≠ncrona del sistema se regir√° por un conjunto bien definido de eventos de dominio. Cada evento representa un cambio de estado significativo dentro de un l√≠mite de dominio (un slice vertical).

Los eventos seguir√°n el patr√≥n de **Transferencia de Estado Llevada por Evento (Event-Carried State Transfer)**, donde la carga √∫til del evento contiene toda la informaci√≥n necesaria para que los consumidores act√∫en sin necesidad de consultar al servicio de origen para obtener m√°s datos. Esto mejora el desacoplamiento y la resiliencia.8

### **Tabla: Cat√°logo de Eventos de Dominio**

**Prop√≥sito:** Esta tabla sirve como un registro central para todos los mensajes as√≠ncronos en el sistema. Asegura que todos los equipos tengan una comprensi√≥n clara y consistente de los eventos, su prop√≥sito y sus estructuras de datos, lo cual es cr√≠tico para mantener una arquitectura d√©bilmente acoplada. Act√∫a como la "especificaci√≥n OpenAPI" para la parte as√≠ncrona de nuestro sistema, obligando a los desarrolladores a pensar expl√≠citamente sobre los datos que necesitan ser comunicados entre slices y promoviendo el patr√≥n de Transferencia de Estado Llevada por Evento.15


| Nombre del Evento | Slice Emisor             | Descripci√≥n                                                                    | Esquema de Carga √ötil (JSON Schema)                                                                                   | Consumidores Potenciales                       |
| :---------------- | :----------------------- | :------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------- |
| ArtifactUploaded  | Ingesta de Artefactos    | Se dispara cuando un nuevo artefacto ha sido subido y almacenado con √©xito.    | { "artifactId": "...", "repository": "...", "version": "...", "sha256": "...", "uploader": "..." }                     | B√∫squeda, Escaneo de Seguridad, Notificaci√≥n |
| RepositoryCreated | Gesti√≥n de Repositorios | Se dispara cuando se crea un nuevo espacio de nombres de repositorio.           | { "repositoryId": "...", "path": "...", "visibility": "private", "creator": "..." }                                    | Auditor√≠a, Control de Acceso                  |
| ScanCompleted     | Escaneo de Seguridad     | Se dispara cuando se completa un escaneo de vulnerabilidades para un artefacto. | { "artifactId": "...", "status": "succeeded/failed", "vulnerabilityCount": { "critical": 0,... }, "reportUrl": "..." } | Notificaci√≥n, Aplicaci√≥n de Pol√≠ticas       |

### **7.3. Manejo de Errores As√≠ncronos: Dead Letter Queues (DLQs)**

Para cada tema principal de Kafka, se aprovisionar√° un tema de Dead Letter Queue (DLQ) correspondiente (por ejemplo, artifact-uploads \-\> artifact-uploads-dlq).

Si un consumidor no logra procesar un mensaje despu√©s de un n√∫mero configurado de reintentos (por ejemplo, 3 intentos con retroceso exponencial), el mensaje se mover√° a la DLQ.35

El mensaje movido a la DLQ se aumentar√° con metadatos sobre el fallo, como el mensaje de error, el ID del grupo de consumidores y la marca de tiempo del fallo.

Se configurar√° una monitorizaci√≥n y alertas dedicadas para todas las DLQs para notificar al equipo de operaciones sobre fallos de procesamiento que requieran intervenci√≥n manual. El objetivo es manejar errores transitorios con reintentos y errores persistentes a trav√©s de la DLQ, evitando que un solo mensaje defectuoso detenga todo un pipeline de procesamiento.35

Los consumidores deben ser dise√±ados para ser **idempotentes**. Dado que Kafka proporciona sem√°ntica de entrega de al menos una vez, un consumidor podr√≠a recibir el mismo mensaje m√°s de una vez. El patr√≥n est√°ndar ser√° rastrear los IDs de los mensajes procesados en la base de datos para evitar el procesamiento duplicado.37

## **8\. Requisitos No Funcionales (NFRs)**

Estos requisitos definen los atributos de calidad del sistema y son tan cr√≠ticos como los requisitos funcionales.

### **8.1. Rendimiento y Escalabilidad**

El sistema debe estar dise√±ado para un alto rendimiento y baja latencia, particularmente para la ingesta y recuperaci√≥n de artefactos, que est√°n en la ruta cr√≠tica para los pipelines de CI/CD.

La pila tecnol√≥gica de Rust, incluyendo el framework web axum y el tiempo de ejecuci√≥n tokio, fue elegida espec√≠ficamente para cumplir estos objetivos.40 Puede ser necesario un ajuste de rendimiento del tiempo de ejecuci√≥n de Tokio para escenarios de latencia ultra baja.43

### **Tabla: Objetivos de Rendimiento**

**Prop√≥sito:** Establecer metas de rendimiento claras, medibles y no negociables. Esta tabla transforma requisitos vagos como "r√°pido" en objetivos de ingenier√≠a concretos que pueden ser validados a trav√©s de pruebas de carga. Definir percentiles (p95, p99) es crucial para entender la latencia de cola, que es lo que los usuarios perciben como "lentitud".43 Los objetivos de rendimiento dictan la capacidad del sistema y son esenciales para la planificaci√≥n de la infraestructura y la configuraci√≥n del autoescalado.


| M√©trica              | Operaci√≥n                                          | Objetivo (al 80% de capacidad) |
| :-------------------- | :-------------------------------------------------- | :----------------------------- |
| Latencia de API (p95) | Subida de Artefacto (procesamiento de metadatos)    | \< 100ms                       |
| Latencia de API (p99) | Descarga de Artefacto (generaci√≥n de redirecci√≥n) | \< 50ms                        |
| Latencia de API (p95) | B√∫squeda de Metadatos                              | \< 200ms                       |
| Rendimiento           | Ingestas de Artefactos                              | \> 500 artefactos/minuto       |
| Rendimiento           | Descargas de Artefactos                             | \> 5,000 artefactos/minuto     |

### **8.2. Seguridad e Integridad de la Cadena de Suministro de Software**

* **Cifrado de Datos:** Todos los datos deben ser cifrados tanto en tr√°nsito (TLS 1.3 para toda la comunicaci√≥n de red) como en reposo (utilizando las caracter√≠sticas de cifrado nativas del almacenamiento compatible con S3 y MongoDB).45
* **Comunicaci√≥n Segura:** La comunicaci√≥n con el cl√∫ster de Kafka debe ser asegurada utilizando SASL para la autenticaci√≥n y TLS para el cifrado.48
* **Escaneo de Vulnerabilidades:** El pipeline de CI/CD debe incluir un paso obligatorio para escanear todas las dependencias de Rust en busca de vulnerabilidades conocidas utilizando cargo-audit.51 Las compilaciones con vulnerabilidades cr√≠ticas deben fallar.
* **Generaci√≥n de SBOM:** Por cada artefacto construido y almacenado, se debe generar una Lista de Materiales de Software (SBOM) en formato CycloneDX utilizando herramientas como cargo-sbom o cargo-cyclonedx.54 Este SBOM se almacenar√° junto con el artefacto.
* **Firma de Artefactos:** Todas las im√°genes de contenedores y artefactos binarios cr√≠ticos producidos por el pipeline de CI/CD deben ser firmados criptogr√°ficamente utilizando cosign con un flujo de firma sin clave que aproveche el proveedor OIDC de GitLab. La firma debe ser verificable contra el registro de transparencia.56

### **8.3. Observabilidad**

* **Registro (Logging):** Todos los servicios deben producir registros estructurados (formato JSON) que contengan un ID de correlaci√≥n para rastrear una √∫nica solicitud a trav√©s de m√∫ltiples servicios/slices.
* **M√©tricas:** Todos los servicios deben exponer un punto final /metrics en formato Prometheus, proporcionando m√©tricas clave de la aplicaci√≥n (por ejemplo, tasas de solicitud, tasas de error, latencias) y m√©tricas de tiempo de ejecuci√≥n (por ejemplo, uso de memoria, pausas de GC).
* **Trazado (Tracing):** El trazado distribuido utilizando el est√°ndar OpenTelemetry es obligatorio. Cada solicitud de API entrante y cada evento publicado debe iniciar o propagar una traza, permitiendo la visualizaci√≥n de todo el ciclo de vida de la solicitud a trav√©s de diferentes slices y l√≠mites as√≠ncronos.59

## **9\. Pila Tecnol√≥gica y Estrategia de Despliegue**

### **9.1. Tecnolog√≠as Centrales**

* **Lenguaje/Tiempo de Ejecuci√≥n:** Rust (√∫ltima versi√≥n estable) con el tiempo de ejecuci√≥n as√≠ncrono Tokio.42
* **Framework Web:** Axum, por su rendimiento, ergonom√≠a y estrecha integraci√≥n con el ecosistema de Tokio.40
* **Almacenamiento de Metadatos:** MongoDB, por su esquema flexible y potentes capacidades de indexaci√≥n, accedido a trav√©s del driver oficial de Rust.22
* **Almacenamiento de Objetos:** Cualquier servicio compatible con S3 (por ejemplo, AWS S3, MinIO), accedido a trav√©s de la crate de Rust aws-sdk-s3, configurado con un punto final personalizado para pruebas locales.20
* **Bus de Eventos:** Apache Kafka, por su alto rendimiento y durabilidad, accedido a trav√©s de la biblioteca de Rust rdkafka.64

### **9.2. Contenerizaci√≥n y Orquestaci√≥n**

La aplicaci√≥n se empaquetar√° como una imagen Docker m√≠nima de varias etapas, basada en una imagen base delgada (por ejemplo, debian:bullseye-slim) para reducir la superficie de ataque y el tama√±o de la imagen.67

El despliegue se gestionar√° a trav√©s de Kubernetes. Se crear√° un Helm chart completo para definir todos los recursos de Kubernetes necesarios (Deployments, Services, ConfigMaps, Secrets, etc.), permitiendo despliegues repetibles y versionados.68

### **9.3. Pipeline de CI/CD (GitLab CI)**

El pipeline, definido en .gitlab-ci.yml, ser√° el √∫nico camino a producci√≥n. Constar√° de las siguientes etapas obligatorias:

1. **Lint & Format:** Ejecutar cargo fmt y cargo clippy para hacer cumplir el estilo de c√≥digo y detectar errores comunes.
2. **Build:** Compilar la aplicaci√≥n en modo de lanzamiento (cargo build \--release).
3. **Unit & Integration Test:** Ejecutar cargo test. Las pruebas de integraci√≥n utilizar√°n la biblioteca **Testcontainers** para levantar contenedores Docker ef√≠meros para dependencias como Kafka, MongoDB y MinIO, asegurando que las pruebas se ejecuten en un entorno limpio y aislado que refleje la producci√≥n.71
4. **Security Scan:** Ejecutar cargo-audit para buscar vulnerabilidades y cargo-deny para verificar la conformidad de las licencias.51
5. **Build & Push Image:** Construir la imagen Docker y subirla al Registro de Contenedores de GitLab, etiquetada con el SHA del commit.74
6. **Sign Artifacts:** Generar un SBOM y firmar la imagen del contenedor usando cosign.56
7. **Deploy to Staging:** Desplegar autom√°ticamente la imagen firmada en un entorno de Kubernetes de staging utilizando el Helm chart.
8. **Promote to Production:** Un paso de aprobaci√≥n manual para promover la imagen verificada al entorno de producci√≥n.

### **9.4. Estrategia de Promoci√≥n de Im√°genes**

Se implementar√° una estrategia clara y automatizada para promover im√°genes entre entornos dentro del Registro de Contenedores de GitLab.

* **Desarrollo:** Cada commit a una rama de funcionalidad construye una imagen etiquetada con el SHA del commit (por ejemplo, registry.example.com/group/project:sha-abcdef12).
* **Staging:** Cuando una solicitud de fusi√≥n se combina en la rama main, el pipeline de CI construye, prueba y firma la imagen. Si tiene √©xito, la imagen se re-etiqueta como staging y se despliega en el entorno de staging.75
* **Producci√≥n:** Despu√©s de una validaci√≥n exitosa en staging, un trabajo de pipeline manual o una etiqueta de Git activa la promoci√≥n. Esto implica re-etiquetar el mismo digest de imagen (que fue firmado y probado) con una etiqueta de versi√≥n (por ejemplo, v1.2.3) y la etiqueta latest. Esto asegura que el artefacto desplegado en producci√≥n es exactamente el mismo que fue verificado, evitando cualquier manipulaci√≥n.75 Este re-etiquetado y env√≠o es el n√∫cleo de la estrategia de promoci√≥n, garantizando la inmutabilidad entre entornos.

## **Anexo A: Historias de Usuario para Arquitectura de Slice Vertical (VSA)**

## üéØ Visi√≥n General

Sistema de repositorio de artefactos con capacidades avanzadas de seguridad, construido en Rust con arquitectura de **Vertical Slices**, inspirado en el an√°lisis de JFrog Artifactory y XRay.

## üèóÔ∏è Arquitectura de Vertical Slices

### üìã **Slice 1: Upload de Artefactos con Validaci√≥n de Seguridad**

**Descripci√≥n**: Upload de artefactos con escaneo proactivo de vulnerabilidades

```plaintext
API Endpoints:
  - POST /v1/artifacts/{repoType}/{groupId}/{artifactId}/{version}
  - POST /v1/artifacts/multipart (large files)

Componentes Core:
  - ArtifactUploadService
  - SecurityScannerIntegration
  - ChecksumValidator
  - MetadataExtractor

Adaptadores:
  - MinIOStorageAdapter
  - MongoDBArtifactRepository
  - CedarPolicyAuthorizer
  - VulnerabilityScannerAdapter

Eventos:
  - ArtifactUploadedEvent
  - SecurityScanStartedEvent
  - VulnerabilityDetectedEvent
```

### üì• **Slice 2: Download Seguro con Control de Acceso**

**Descripci√≥n**: Distribuci√≥n de artefactos con pol√≠ticas granulares de acceso

```plaintext
API Endpoints:
  - GET /v1/artifacts/{repoType}/{groupId}/{artifactId}/{version}
  - GET /v1/artifacts/{repoType}/{groupId}/{artifactId}/{version}/content

Componentes Core:
  - ArtifactDownloadService
  - AccessControlService
  - LicenseValidator
  - UsageTracker

Adaptadores:
  - MinIODownloadAdapter
  - CDNDistributionAdapter
  - CedarPolicyEngine

Optimizaciones:
  - Range requests support
  - Conditional GET (ETag/If-Modified-Since)
  - Cache control headers
```

### üîç **Slice 3: B√∫squeda y An√°lisis de Dependencias**

**Descripci√≥n**: B√∫squeda avanzada con an√°lisis de dependencias transitivas

```plaintext
API Endpoints:
  - GET /v1/search/artifacts?q={query}
  - GET /v1/search/dependencies?package={packageName}
  - POST /v1/analysis/dependency-graph

Componentes Core:
  - DependencyAnalysisService
  - VulnerabilityAggregator
  - LicenseComplianceChecker
  - SBOMGenerator

Adaptadores:
  - GraphDatabaseAdapter (Neo4j/JanusGraph)
  - ElasticSearchAdapter
  - MongoDBIndexAdapter

Caracter√≠sticas:
  - Full-text search avanzado
  - An√°lisis de dependencias transitivas
  - Detecci√≥n de conflictos de licencias
  - Generaci√≥n autom√°tica de SBOM
```

### üë• **Slice 4: Gesti√≥n de Usuarios y Pol√≠ticas ABAC**

**Descripci√≥n**: Sistema completo de gesti√≥n de acceso basado en atributos

```plaintext
API Endpoints:
  - POST /v1/users (crear usuario)
  - PUT /v1/users/{userId}/policies
  - GET /v1/groups/{groupId}/members
  - POST /v1/policies/validate

Componentes Core:
  - UserManagementService
  - PolicyManagementService
  - AccessDecisionPoint
  - AuditLogger

Adaptadores:
  - MongoDBUserRepository
  - CedarPolicyEngineAdapter
  - LDAP/AD Integration
  - SAML/OIDC Provider

Pol√≠ticas ABAC:
  - Basadas en atributos de usuario
  - Basadas en propiedades de artefactos
  - Basadas en contexto de seguridad
  - Basadas en riesgo operacional
```

### üèóÔ∏è **Slice 5: Administraci√≥n de Repositorios Virtuales**

**Descripci√≥n**: Creaci√≥n y gesti√≥n de repositorios virtuales agregados

```plaintext
API Endpoints:
  - POST /v1/repositories (crear repositorio)
  - PUT /v1/repositories/{repoId}/settings
  - POST /v1/repositories/{repoId}/cleanup
  - GET /v1/repositories/{repoId}/stats

Componentes Core:
  - RepositoryManager
  - RetentionPolicyEngine
  - StorageQuotaService
  - ReplicationCoordinator

Adaptadores:
  - MongoDBRepoRepository
  - MinIOQuotaAdapter
  - CrossRegionReplicator

Caracter√≠sticas:
  - Pol√≠ticas de retenci√≥n autom√°tica
  - Quotas de almacenamiento granular
  - R√©plica autom√°tica multi-regi√≥n
  - Limpieza inteligente de artefactos
```

### üìä **Slice 6: Monitorizaci√≥n y Analytics de Seguridad**

**Descripci√≥n**: Sistema completo de monitorizaci√≥n y an√°lisis de seguridad

```plaintext
API Endpoints:
  - GET /metrics (formato Prometheus)
  - GET /v1/security/dashboard
  - GET /v1/audit/logs
  - POST /v1/security/reports

Componentes Core:
  - SecurityMetricsCollector
  - VulnerabilityTrendAnalyzer
  - ComplianceAuditor
  - RiskAssessmentEngine

Adaptadores:
  - PrometheusExporter
  - OpenTelemetryAdapter
  - SIEMIntegrationAdapter
  - GrafanaDashboardManager

M√©tricas Clave:
  - Vulnerability distribution por severidad
  - Compliance status por proyecto
  - Risk score evolution
  - Security policy violation trends
```

### üîê **Slice 7: Autenticaci√≥n Federada y SSO**

**Descripci√≥n**: Sistema de autenticaci√≥n unificada con federaci√≥n

```plaintext
API Endpoints:
  - POST /v1/auth/login
  - POST /v1/auth/token/refresh
  - GET /v1/auth/userinfo
  - POST /v1/auth/federation/sync

Componentes Core:
  - AuthenticationService
  - TokenManagementService
  - FederationService
  - SessionManager

Adaptadores:
  - LDAPAuthAdapter
  - OIDCProviderAdapter
  - SAMLServiceProvider
  - ActiveDirectorySync

Caracter√≠sticas:
  - Multi-factor authentication
  - Token revocation distribuida
  - Session clustering
  - Cross-instance federation
```

### üöÄ **Slice 8: Deployment y Configuraci√≥n Cloud-Native**

**Descripci√≥n**: Gesti√≥n de despliegues y configuraci√≥n en entornos cloud

```plaintext
API Endpoints:
  - GET /v1/config/current
  - POST /v1/config/update
  - GET /v1/health (health checks)
  - GET /v1/cluster/status

Componentes Core:
  - ConfigurationManager
  - DeploymentOrchestrator
  - HealthCheckService
  - ClusterCoordinator

Adaptadores:
  - KubernetesOperatorAdapter
  - ConsulConfigAdapter
  - VaultSecretManager
  - CloudMetadataService

Caracter√≠sticas:
  - Hot-reload de configuraci√≥n
  - Health checks personalizables
  - Auto-scaling autom√°tico
  - Zero-downtime deployments
```

### üì¶ **Slice 9: Soporte Multi-Formato con Escaneo Integrado**

**Descripci√≥n**: Soporte para m√∫ltiples formatos de paquetes con escaneo de seguridad

```plaintext
Formatos Soportados:
  - Maven (Java)
  - npm (JavaScript)
  - Docker (OCI)
  - NuGet (.NET)
  - PyPI (Python)
  - Go modules
  - RubyGems
  - Helm charts

Componentes Core:
  - PackageFormatDetector
  - MetadataExtractor
  - VulnerabilityMatcher
  - LicenseDetector

Adaptadores Espec√≠ficos:
  - MavenMetadataAdapter
  - NpmPackageAnalyzer
  - DockerManifestScanner
  - NuGetDependencyResolver

Caracter√≠sticas:
  - Detecci√≥n autom√°tica de formato
  - Extracci√≥n de metadatos enriquecidos
  - Escaneo recursivo de dependencias
  - Detecci√≥n de licencias autom√°tica
```

### üîÑ **Slice 10: Event-Driven Security Pipeline**

**Descripci√≥n**: Procesamiento as√≠ncrono de eventos de seguridad

```plaintext
Eventos Principales:
  - ArtifactUploadedEvent
  - SecurityScanCompletedEvent
  - VulnerabilityDetectedEvent
  - PolicyViolationEvent
  - LicenseComplianceEvent

Componentes Core:
  - EventDispatcher
  - SecurityPipelineManager
  - IncidentResponseCoordinator
  - WorkflowOrchestrator

Adaptadores:
  - KafkaEventAdapter
  - RabbitMQIntegration
  - WebhookDispatcher
  - NotificationService

Caracter√≠sticas:
  - Processing pipeline configurable
  - Dead-letter queue management
  - Retry mechanisms with backoff
  - Event sourcing for audit
```

## üéØ Criterios de Implementaci√≥n por Slice

Cada Vertical Slice debe implementar:

### ‚úÖ **Contract First Development**

- Especificaci√≥n OpenAPI completa para cada endpoint
- Client SDK generado autom√°ticamente
- Validaci√≥n autom√°tica de requests/responses
- Versionado sem√°ntico de APIs

### ‚úÖ **Hexagonal Architecture**

- Puertos claramente definidos para cada adaptador
- Testabilidad mediante mocking de adaptadores
- Replaceability de componentes externos

### ‚úÖ **Security by Design**

- Validaci√≥n de inputs en todos los endpoints
- Autorizaci√≥n con pol√≠ticas Cedar
- Audit logging de todas las operaciones
- Encryption de datos sensibles

### ‚úÖ **Performance Optimization**

- Streaming eficiente para grandes archivos
- Caching estrat√©gico de metadatos
- Concurrencia optimizada con async/await
- Database indexing avanzado

### ‚úÖ **Observability**

- Metrics exposici√≥n en formato Prometheus
- Distributed tracing con OpenTelemetry
- Structured logging en JSON
- Health checks personalizables

## üìä M√©tricas por Slice

Cada slice debe exponer m√©tricas espec√≠ficas:


| Slice    | M√©tricas Clave                         | Objetivo                      |
| -------- | --------------------------------------- | ----------------------------- |
| Upload   | Throughput, Latencia p95, Tasa de error | >100 RPS, <100ms p95          |
| Download | Bandwidth, Cache hit rate, Latencia     | >1 Gbps, >90% hit rate        |
| Search   | Query latency, Recall rate              | <50ms p95, >95% recall        |
| Security | Scan time, Vulnerability detection rate | <30s por scan, >99% detection |

## üîÑ Dependencies entre Slices

```
Security Pipeline ‚Üí Upload, Download, Search
Authentication ‚Üí All Slices
Monitoring ‚Üí All Slices
Event System ‚Üí Multiple Slices
```

## üöÄ Roadmap de Implementaci√≥n

### Fase 1: Core Artifactory (2-3 meses)

1. **Slice 1**: Upload de artefactos con validaci√≥n b√°sica
2. **Slice 2**: Download con control de acceso
3. **Slice 9**: Soporte para Maven y npm
4. **Slice 4**: Autenticaci√≥n b√°sica y pol√≠ticas

### Fase 2: XRay Integration (2-3 meses)

1. **Slice 3**: An√°lisis de dependencias y vulnerabilidades
2. **Slice 6**: Dashboard de seguridad y m√©tricas
3. **Slice 10**: Event-driven security pipeline
4. **Slice 5**: Repository management avanzado

### Fase 3: Enterprise Features (3-4 meses)

1. **Slice 7**: Federaci√≥n y SSO
2. **Slice 8**: Deployment cloud-native
3. **Slice 9**: Soporte para formatos adicionales
4. **Slice 6**: Advanced analytics y reporting

## üí° Innovaciones sobre Artifactory/XRay

1. **Rust-native performance**: Mejor rendimiento y menor uso de memoria
2. **MinIO first**: Soporte nativo para almacenamiento S3-compatible
3. **Cedar integration**: Pol√≠ticas de autorizaci√≥n m√°s expresivas
4. **WebAssembly plugins**: Sistema extensible mediante plugins seguros
5. **OpenTelemetry native**: Observabilidad consistente across todos los componentes

Este dise√±o permite desarrollar cada feature de manera independiente mientras mantiene consistencia arquitect√≥nica y facilita la integraci√≥n de capacidades avanzadas de seguridad inspiradas en XRay.

---

# An√°lisis Cr√≠tico del Modelo de Datos Propuesto

## ‚úÖ Aspectos Positivos del Modelo Actual

### 1. **Identificaci√≥n Clara de Artefactos**

- El uso de `ArtifactCoordinates` con group, name, version, classifier y extension es s√≥lido y sigue convenciones est√°ndar de Maven/npm
- La generaci√≥n de hash can√≥nico para identificaci√≥n √∫nica es una buena pr√°ctica

### 2. **Gesti√≥n de Estados del Ciclo de Vida**

- `ArtifactStatus` cubre todos los estados necesarios (ACTIVE, DEPRECATED, QUARANTINED, etc.)
- Los estados permiten un control granular del ciclo de vida de los artefactos

### 3. **Soporte para SBOM y Verificaci√≥n de Integridad**

- La inclusi√≥n de `SbomDocument` y `MerkleGraph` es exhaustiva y adecuada para seguridad de supply chain
- La estructura de componentes y relaciones en SBOM sigue est√°ndares como CycloneDX

### 4. **Metadatos Completos**

- `ArtifactMetadata` contiene toda la informaci√≥n necesaria para trazabilidad y descubrimiento
- Los checksums m√∫ltiples apoyan la verificaci√≥n de integridad

## ‚ö†Ô∏è Aspectos a Mejorar

### 1. **Complejidad y Acoplamiento**

- El modelo actual est√° muy acoplado a conceptos espec√≠ficos de Java/Kotlin (classifier, extension)
- La estructura es compleja para algunos ecosistemas m√°s simples (npm, Python)

### 2. **Rendimiento en Base de Datos**

- Las estructuras anidadas profundas (como MerkleGraph) pueden ser dif√≠ciles de indexar y consultar en MongoDB
- La normalizaci√≥n excesiva podr√≠a afectar el rendimiento de consultas frecuentes

### 3. **Falta de Soporte para Almacenamiento de Binarios**

- No hay referencia expl√≠cita al almacenamiento f√≠sico de los artefactos binarios
- Falta informaci√≥n sobre c√≥mo se gestiona el contenido en MinIO/S3

### 4. **Gesti√≥n de Permisos y Acceso**

- El modelo no incluye informaci√≥n sobre control de acceso a nivel de artefacto/repositorio
- No hay integraci√≥n con el sistema de pol√≠ticas ABAC que mencionamos


# Diagrama de Clases para Sistema de Repositorio de Artefactos

```mermaid
classDiagram
    %% Entidades principales
    class Artifact {
        +String id
        +ContentHash contentHash
        +ArtifactCoordinates coordinates
        +List~String~ tags
        +String packagingType
        +Long sizeInBytes
        +ArtifactStatus status
        +ArtifactMetadata metadata
        +List~ArtifactDependency~ dependencies
        +SecurityScan securityScan
    }

    class ArtifactCoordinates {
        +ArtifactGroup group
        +String name
        +ArtifactVersion version
        +ArtifactClassifier classifier
        +ArtifactExtension extension
        +toCanonicalStringForHashing() String
        +sha256() String
    }

    class ArtifactMetadata {
        +ArtifactId id
        +UserId createdBy
        +Instant createdAt
        +String description
        +List~String~ licenses
        +String homepageUrl
        +String repositoryUrl
        +Long sizeInBytes
        +Map~String,String~ checksums
    }

    class ArtifactDependency {
        +ArtifactCoordinates coordinates
        +String scope
        +Boolean isOptional
        +String versionConstraint
    }

    class SecurityScan {
        +String scanId
        +ScanStatus status
        +List~Vulnerability~ vulnerabilities
        +Float riskScore
        +Instant scannedAt
        +String scannerVersion
    }

    class Vulnerability {
        +String cveId
        +VulnerabilitySeverity severity
        +String description
        +Float cvssScore
        +List~String~ fixedVersions
    }

    %% Value Objects
    class ArtifactGroup {
        +String value
    }

    class ArtifactVersion {
        +String value
    }

    class ArtifactClassifier {
        +String value
    }

    class ArtifactExtension {
        +String value
    }

    class ContentHash {
        +String algorithm
        +String value
        +create(content: String, algorithm: String) ContentHash
        +createFromBytes(bytes: ByteArray, algorithm: String) ContentHash
        +toByteArray() ByteArray
    }

    class UserId {
        +String value
    }

    class ArtifactId {
        +String value
    }

    %% Enumeraciones
    class ArtifactStatus {
        <<enumeration>>
        ACTIVE
        PRE_RELEASE
        PENDING
        DEPRECATED
        ARCHIVED
        QUARANTINED
        REJECTED
        DISABLED
        BANNED
        DELETED
        UNKNOWN
    }

    class ScanStatus {
        <<enumeration>>
        PENDING
        IN_PROGRESS
        COMPLETED
        FAILED
        SKIPPED
    }

    class VulnerabilitySeverity {
        <<enumeration>>
        CRITICAL
        HIGH
        MEDIUM
        LOW
        INFO
    }

    %% Relaciones entre clases
    Artifact "1" -- "1" ArtifactCoordinates : tiene
    Artifact "1" -- "1" ArtifactMetadata : tiene
    Artifact "1" -- "1" ContentHash : tiene
    Artifact "1" -- "*" ArtifactDependency : tiene
    Artifact "1" -- "1" SecurityScan : tiene
    SecurityScan "1" -- "*" Vulnerability : contiene
  
    ArtifactCoordinates "1" -- "1" ArtifactGroup : usa
    ArtifactCoordinates "1" -- "1" ArtifactVersion : usa
    ArtifactCoordinates "1" -- "1" ArtifactClassifier : usa
    ArtifactCoordinates "1" -- "1" ArtifactExtension : usa
  
    ArtifactMetadata "1" -- "1" UserId : creado por
    ArtifactMetadata "1" -- "1" ArtifactId : para
  
    ArtifactDependency "1" -- "1" ArtifactCoordinates : referencia
  
    %% Relaciones de composici√≥n/agregaci√≥n
    ArtifactCoordinates -- Artifact : compone
    ArtifactMetadata -- Artifact : compone
    ContentHash -- Artifact : compone
    ArtifactDependency -- Artifact : compone
    SecurityScan -- Artifact : compone
    Vulnerability -- SecurityScan : compone
```

## Diagrama Adicional para SBOM y Merkle Tree

```mermaid
classDiagram
    %% Entidades de SBOM
    class SbomDocument {
        +String artifactId
        +SbomFormat format
        +String specVersion
        +List~SbomComponent~ components
        +List~SbomRelationship~ relationships
        +Instant creationTime
        +List~ToolInformation~ tools
        +List~ContactInformation~ authors
        +String serialNumber
        +String documentName
        +String documentNamespace
        +String describesComponentRef
        +List~ExternalReference~ externalReferences
        +String dataLicense
    }

    class SbomComponent {
        +String group
        +String name
        +String version
        +String type
        +ComponentScope scope
        +List~String~ licenses
        +String description
        +String supplier
        +String purl
        +String cpe
        +String swidTagId
        +String copyright
        +Map~String,String~ hashes
        +List~ExternalReference~ externalReferences
        +Map~String,String~ properties
        +List~SbomComponent~ components
    }

    class SbomRelationship {
        +String type
        +String fromComponentId
        +String toComponentId
    }

    class ExternalReference {
        +String type
        +String url
        +String comment
    }

    class ToolInformation {
        +String name
        +String version
        +String vendor
        +Map~String,String~ hashes
    }

    class ContactInformation {
        +String name
        +String email
        +String phone
        +String role
    }

    %% Enumeraciones SBOM
    class SbomFormat {
        <<enumeration>>
        CYCLONE_DX
        SPDX
    }

    class ComponentScope {
        <<enumeration>>
        REQUIRED
        OPTIONAL
        EXCLUDED
        RUNTIME
    }

    %% Entidades de Merkle Tree
    class MerkleGraph {
        +String artifactId
        +MerkleNode rootNode
        +List~Signature~ signatures
        +ContentHash rootHash
        +addSignature(signature: Signature) MerkleGraph
        +isGraphValid() Boolean
    }

    class MerkleNode {
        +String path
        +ContentHash contentHash
        +MerkleNodeType nodeType
        +List~MerkleNode~ children
        +computeHash(path: String, children: List~MerkleNode~, algorithm: String) MerkleNode
    }

    class Signature {
        +String value
        +String algorithm
        +ContentHash contentHash
        +String keyId
        +Instant creationTime
    }

    class MerkleNodeType {
        <<enumeration>>
        FILE
        DIRECTORY
    }

    %% Relaciones entre clases
    SbomDocument "1" -- "*" SbomComponent : contiene
    SbomDocument "1" -- "*" SbomRelationship : contiene
    SbomDocument "1" -- "*" ExternalReference : tiene
    SbomDocument "1" -- "*" ToolInformation : tiene
    SbomDocument "1" -- "*" ContactInformation : tiene
  
    SbomComponent "1" -- "*" SbomComponent : puede contener
    SbomComponent "1" -- "*" ExternalReference : puede tener
  
    MerkleGraph "1" -- "1" MerkleNode : tiene como ra√≠z
    MerkleGraph "1" -- "*" Signature : tiene
    MerkleNode "1" -- "*" MerkleNode : puede tener hijos
```

## Explicaci√≥n del Diagrama

Este diagrama de clases representa el modelo de datos para un sistema de repositorio de artefactos con las siguientes caracter√≠sticas:

1. **Artefactos y sus componentes**: La clase principal `Artifact` contiene toda la informaci√≥n sobre un artefacto, incluyendo sus coordenadas, metadatos, dependencias y resultados de escaneo de seguridad.
2. **Sistema de coordenadas**: `ArtifactCoordinates` utiliza value objects para group, name, version, classifier y extension, siguiendo las convenciones de diferentes ecosistemas de paquetes.
3. **Verificaci√≥n de integridad**: El sistema utiliza `ContentHash` para verificaci√≥n de integridad y soporta m√∫ltiples algoritmos de hash.
4. **Gesti√≥n de seguridad**: `SecurityScan` y `Vulnerability` permiten realizar y almacenar escaneos de seguridad con informaci√≥n detallada sobre vulnerabilidades.
5. **SBOM (Software Bill of Materials)**: El sistema soporta la generaci√≥n y gesti√≥n de SBOMs con los formatos CycloneDX y SPDX, incluyendo componentes, relaciones y referencias externas.
6. **Merkle Trees**: Para verificaci√≥n avanzada de integridad, el sistema implementa grafos de Merkle que permiten verificar la autenticidad de los artefactos mediante firmas digitales.
7. **Sistema de tipos**: Se utilizan enumeraciones para gestionar estados, severidades y tipos de manera consistente en todo el sistema.

Este modelo de datos est√° dise√±ado para ser extensible y soportar los diferentes vertical slices identificados, proporcionando una base s√≥lida para la implementaci√≥n del repositorio de artefactos.
