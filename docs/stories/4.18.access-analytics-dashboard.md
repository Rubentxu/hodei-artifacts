### **Historia 4.18: Access Analytics Dashboard**

#### **Proceso de Creación**
* **Identificada siguiente historia:** 4.18 - Access Analytics Dashboard.
* **Recopilación:** Esta historia se basa en los datos generados por el `AuditTrailSystem` (historia 4.9). El objetivo es procesar esos datos brutos para convertirlos en métricas de alto nivel y exponerlos a través de una API para que un futuro dashboard pueda consumirlos.
* **Checklist:** Ejecutando la `story-draft-checklist`... **Resultado:** ✅ **LISTA**.

#### **Archivo: `docs/stories/4.18.Access-Analytics-Dashboard.md`**

# Historia 4.18: Access Analytics Dashboard

## Estado
- **Borrador (Draft)**

## Historia
**Como** administrador de seguridad,
**quiero** un dashboard con métricas y análisis de las decisiones de acceso,
**para que** pueda auditar el uso de permisos, detectar anomalías y entender los patrones de acceso.

## Criterios de Aceptación
1.  Se ha creado un `AccessAnalyticsService` que procesa los datos del `AuditTrail` para generar estadísticas.
2.  Existe un endpoint de API (`GET /api/v1/analytics/summary`) que devuelve métricas clave, como el número total de decisiones `Allow` vs `Deny` en un período de tiempo.
3.  Existe un endpoint de API que devuelve los "top N" principales con más accesos denegados.
4.  Existe un endpoint de API que devuelve los "top N" recursos a los que más se accede.
5.  El servicio de análisis puede funcionar en segundo plano para pre-calcular las métricas y asegurar que las consultas a la API sean rápidas.
6.  Se publica un evento `AccessAnalyticsUpdated` cuando las métricas han sido recalculadas.

## Tareas / Subtareas
- [ ] **Tarea 1: Implementar el Servicio de Analíticas** (AC: #1)
    - [ ] Crear el `AccessAnalyticsService`.
    - [ ] Implementar métodos que lean del `AuditStorage` (de la historia 4.9) y agreguen los datos.
- [ ] **Tarea 2: Implementar la Lógica de Agregación** (AC: #2, #3, #4)
    - [ ] Escribir las consultas o la lógica para calcular las métricas (p. ej., conteo de `Allow`/`Deny`, agrupaciones por principal y recurso).
- [ ] **Tarea 3: Implementar el Procesamiento en Segundo Plano** (AC: #5)
    - [ ] Crear un job programado (p. ej., cada hora) que ejecute el servicio de análisis y guarde los resultados agregados en una caché (p. ej., Redis) para un acceso rápido.
- [ ] **Tarea 4: Implementar los Endpoints de la API**
    - [ ] Añadir e implementar los endpoints de la API de analíticas en la especificación OpenAPI. Estos endpoints deben leer los datos pre-calculados de la caché.
- [ ] **Tarea 5: Publicar Evento de Dominio** (AC: #6)
    - [ ] Al final del job de procesamiento, publicar el evento `AccessAnalyticsUpdated`.
- [ ] **Tarea 6: Añadir Pruebas**
    - [ ] Escribir pruebas unitarias para la lógica de agregación.
    - [ ] Escribir pruebas de integración para los endpoints de la API, verificando que devuelven los datos agregados correctamente.

## Notas para el Desarrollador
Esta historia se centra en el backend y la API para el dashboard. La implementación de la interfaz de usuario (UI) no forma parte de esta historia.

### Fuente de Datos
* La única fuente de datos para este servicio debe ser el `AuditTrail` creado en la historia 4.9. Esto asegura que las métricas reflejan fielmente las decisiones de autorización que realmente se tomaron.

### Optimización del Rendimiento
* Analizar el log de auditoría completo puede ser lento. Es fundamental pre-calcular y cachear los resultados. Un job que se ejecuta periódicamente es un patrón adecuado para esto. Las APIs de analíticas deben ser muy rápidas y leer estos resultados cacheados, no calcularlos en tiempo real.