# Story 1.5: Detecci√≥n de Duplicados

## Status

Draft

## Story

**As a** System,
**I want** to detect when an uploaded artifact's content (based on its hash) already exists in the system,
**so that** I can avoid storing the same binary data multiple times and save storage space.

## Acceptance Criteria

1. Before storing a new artifact binary, the system must check if a `PhysicalArtifact` with the same content hash already exists.
2. If a duplicate hash is found, the system must not re-upload the binary data to object storage.
3. Instead, a new `ArtifactReference` should be created for the new `PackageVersion`, pointing to the existing `PhysicalArtifact`.
4. The `PackageVersion` metadata should be created as new, as it represents a new logical artifact.
5. A `DuplicateArtifactDetected` event should be published for analytics.
6. This check must be performant to not significantly slow down uploads.

## Tasks / Subtasks

- [ ] Add a query method to the `PhysicalArtifact` repository to find an artifact by its content hash.
- [ ] Integrate this check into the artifact upload workflow before the file is streamed to S3.
- [ ] If a duplicate is found, bypass the S3 upload and use the existing `PhysicalArtifact`'s HRN.
- [ ] Ensure the `PackageVersion` is still created correctly.
- [ ] Implement the `DuplicateArtifactDetected` event.
- [ ] Consider performance implications (e.g., using a Bloom filter for a quick probabilistic check).

## Dev Notes

### Data Models
- This heavily relies on the separation between `PackageVersion` (logical) and `PhysicalArtifact` (physical).
- `PhysicalArtifact` is identified by its `content_hash`.