# Story 5.6: Repository Statistics

## Status
- Draft

## Story
**Como** un Administrador del Sistema,
**quiero** consultar un panel de estadísticas detalladas para cada repositorio,
**para** poder monitorizar la actividad, entender los patrones de uso y tomar decisiones informadas sobre la gestión del almacenamiento y la popularidad de los artefactos.

## Acceptance Criteria
1.  La API debe exponer un endpoint para obtener las estadísticas de un repositorio.
2.  Las estadísticas deben incluir como mínimo:
    -   Número total de artefactos.
    -   Tamaño total de almacenamiento utilizado (`total_size_bytes`).
    -   Número de descargas en los últimos 30 días.
    -   Fecha y hora de la última subida de un artefacto.
    -   Fecha y hora de la última descarga de un artefacto.
3.  Las estadísticas no se calculan en tiempo real en cada petición, sino que se actualizan periódicamente mediante un proceso en segundo plano.
4.  El proceso de actualización de estadísticas debe ser configurable y ejecutarse al menos una vez al día.
5.  Los datos presentados por la API deben reflejar la última actualización completada con éxito, junto con la marca de tiempo de dicha actualización.

## Tasks / Subtasks
- [ ] Tarea 1: Diseñar el modelo de datos para las estadísticas agregadas. (AC: 2)
    - [ ] Subtarea 1.1: Crear una nueva colección en MongoDB llamada `repository_statistics`.
    - [ ] Subtarea 1.2: Definir la struct `RepositoryStatistics` en Rust, que incluirá campos como `repository_id`, `total_artifacts: u64`, `total_size_bytes: u64`, `downloads_last_30_days: u32`, `last_upload_at: Option<DateTime>`, `last_download_at: Option<DateTime>`, y `last_calculated_at: DateTime`.
- [ ] Tarea 2: Desarrollar el servicio de agregación de estadísticas. (AC: 2, 3)
    - [ ] Subtarea 2.1: Crear un nuevo módulo `StatisticsAggregator` en el `crate` de servicios.
    - [ ] Subtarea 2.2: Implementar la lógica para calcular el número total de artefactos y su tamaño sumado, consultando la colección de artefactos.
    - [ ] Subtarea 2.3: Implementar la lógica para analizar los logs de acceso (o una colección de eventos) para contar las descargas en los últimos 30 días y obtener las fechas de última actividad.
    - [ ] Subtarea 2.4: La función principal del agregador debe tomar un `repository_id`, calcular todas las métricas y guardar el resultado en la colección `repository_statistics`.
- [ ] Tarea 3: Integrar el agregador con el planificador de tareas. (AC: 3, 4)
    - [ ] Subtarea 3.1: Crear un nuevo job en el `tokio-cron-scheduler` (o similar) configurado para ejecutarse periódicamente (ej: cada hora).
    - [ ] Subtarea 3.2: El job iterará sobre todos los repositorios existentes y encolará una tarea de agregación para cada uno, permitiendo la ejecución en paralelo.
- [ ] Tarea 4: Exponer las estadísticas a través de la API. (AC: 1, 5)
    - [ ] Subtarea 4.1: Crear un endpoint de solo lectura `GET /api/v1/repositories/{repo_name}/statistics`.
    - [ ] Subtarea 4.2: La implementación de este endpoint debe ser muy simple: consultar la colección `repository_statistics` por el ID del repositorio y devolver el último documento encontrado. No debe realizar ningún cálculo.
- [ ] Tarea 5: Pruebas.
    - [ ] Subtarea 5.1: Pruebas unitarias para las funciones de cálculo del agregador.
    - [ ] Subtarea 5.2: Pruebas de integración que simulen varias subidas y descargas, ejecuten el job de agregación, y luego verifiquen que el endpoint de la API devuelve las estadísticas correctas.

## Dev Notes

### Relevant Source Tree info
- **ASUNCIÓN**: El servicio de agregación debería residir en `crates/artifactory/src/statistics/aggregator.rs`. El modelo de datos en `crates/artifactory/src/models/statistics.rs`.

### API Specifications
- **ASUNCIÓN**:
    - `GET /api/v1/repositories/{repo_name}/statistics`: No requiere body. La respuesta será un JSON con la estructura de `RepositoryStatistics`, incluyendo la marca de tiempo `last_calculated_at` para que el cliente sepa cuán recientes son los datos.

### Architecture Considerations
- **Decisión Arquitectónica Clave**: Se ha optado por un modelo de **agregación periódica** en lugar de cálculos en tiempo real.
    - **Porqué**: Calcular estadísticas como el número de descargas requiere consultar y procesar una gran cantidad de datos (logs, eventos). Hacerlo en cada petición a la API sería extremadamente ineficiente y no escalaría, resultando en tiempos de respuesta muy altos.
    - **Ventajas**: El endpoint de la API es extremadamente rápido y ligero, ya que solo realiza una lectura simple. La carga de procesamiento se desplaza a un job en segundo plano que puede ser escalado y gestionado de forma independiente.
    - **Desventajas**: Los datos tienen una pequeña latencia (no son 100% en tiempo real). Esta latencia es aceptable para estadísticas de este tipo y es un trade-off necesario para el rendimiento del sistema.

### Testing
- **ASUNCIÓN**: Es fundamental que las pruebas de integración validen el flujo completo: 1) crear actividad en el repositorio, 2) ejecutar el job de agregación manualmente, 3) consultar la API y 4) verificar que los datos coinciden con la actividad creada.