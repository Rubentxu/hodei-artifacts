# Story 1.1: Subida Básica de Artefactos

## Status

Complete

## Story

**As a** CI/CD System,
**I want** to upload an artifact with its basic metadata (name, version, type, checksum),
**so that** it is securely stored and available for retrieval.

## Acceptance Criteria

1. The system must accept artifact uploads via HTTP POST requests
2. Basic metadata must be captured and stored with the artifact
3. Artifact binary content must be stored in S3-compatible object storage
4. Artifact metadata must be persisted in MongoDB
5. An ArtifactUploaded event must be published to Kafka upon successful upload
6. The upload endpoint must enforce authentication and authorization
7. The system must return a unique artifact identifier (HRN format) upon success
8. File integrity must be verified through checksum validation
9. The endpoint must handle large file uploads efficiently
10. Appropriate HTTP status codes must be returned for success and error conditions

## Tasks / Subtasks

- [ ] Implement artifact upload endpoint in Axum (AC: 1, 6, 7, 9, 10)
  - [ ] Create POST /artifacts route handler
  - [ ] Implement multipart/form-data parsing
  - [ ] Add authentication middleware integration
  - [ ] Add authorization checks using IAM/ABAC
  - [ ] Implement request validation
  - [ ] Generate HRN identifier for artifacts
  - [ ] Implement response formatting

- [ ] Implement artifact storage logic (AC: 2, 3, 8)
  - [ ] Create S3 storage adapter implementation
  - [ ] Implement file streaming to object storage
  - [ ] Calculate and validate checksums (SHA-256)
  - [ ] Handle storage errors and retries

- [ ] Implement metadata persistence (AC: 2, 4)
  - [ ] Create MongoDB repository for artifacts
  - [ ] Define artifact metadata schema
  - [ ] Implement save operation with transaction support
  - [ ] Handle database errors and connection issues

- [ ] Implement event publishing (AC: 5)
  - [ ] Create Kafka event publisher adapter
  - [ ] Define ArtifactUploaded event schema
  - [ ] Implement async event publishing with retry logic
  - [ ] Handle event publishing failures

- [ ] Implement error handling and validation (AC: 8, 10)
  - [ ] Create custom error types for artifact operations
  - [ ] Implement input validation for metadata fields
  - [ ] Add proper error mapping to HTTP status codes
  - [ ] Implement logging and tracing

- [ ] Implement unit tests (AC: All)
  - [ ] Test endpoint handler with various input scenarios
  - [ ] Test storage adapter with mock S3 client
  - [ ] Test repository with in-memory MongoDB
  - [ ] Test event publisher with mock Kafka
  - [ ] Test error conditions and edge cases

- [ ] Implement integration tests (AC: All)
  - [ ] Test complete upload flow with test containers
  - [ ] Test authentication and authorization integration
  - [ ] Test event consumption by downstream services
  - [ ] Test performance with large file uploads

## Dev Notes

### Previous Story Insights
This is the first story in the project. No previous story context available.

### Data Models
**Artifact Model** [Source: architecture.md#model-artefacto]
- `id`: String (HRN) - Identificador único del artefacto
- `contentHash`: ContentHash - Hash del contenido para verificar integridad
- `coordinates`: ArtifactCoordinates - Coordenadas (grupo, nombre, versión, clasificador, extensión)
- `packagingType`: String - Tipo de empaquetado (jar, war, npm, docker, etc.)
- `sizeInBytes`: Long - Tamaño en bytes
- `status`: ArtifactStatus - Estado (ACTIVO, DEPRECADO, CUARENTENA)
- `metadata`: ArtifactMetadata - Metadatos detallados
- `repository_id`: String (HRN) - ID del repositorio

**ArtifactCoordinates** [Source: architecture.md#model-artefacto]
- Group, name, version, classifier, extension fields

**ContentHash** [Source: architecture.md#model-artefacto]
- Algorithm (SHA-256)
- Hash value

### API Specifications
**Endpoint**: POST /artifacts [Source: architecture.md#components]
- **Authentication**: Required (JWT tokens)
- **Authorization**: ABAC policies via Cedar engine
- **Content-Type**: multipart/form-data
- **Request Body**:
  - File: artifact binary content
  - Metadata: JSON with basic artifact information
- **Response**: 201 Created with artifact HRN and metadata

**Event Schema**: ArtifactUploaded [Source: architecture.md#core-workflows]
- Published to Kafka bus after successful upload
- Contains artifact ID, metadata, and storage location

### File Locations
**Backend Structure** [Source: architecture.md#components]
- Main crate: `crates/artifact/`
- Feature module: `crates/artifact/src/features/upload_artifact/`
- Domain models: `crates/artifact/src/domain/`
- API handlers: `crates/artifact/src/features/upload_artifact/api.rs`
- Storage adapters: `crates/artifact/src/infrastructure/storage.rs`
- Repository: `crates/artifact/src/infrastructure/persistence.rs`
- Event publisher: `crates/artifact/src/infrastructure/rabbitmq_event_publisher.rs`

### Testing Requirements
**Unit Tests** [Source: architecture.md#test-strategy-and-standards]
- Location: `crates/artifact/src/features/upload_artifact/upload_artifact_test.rs`
- Framework: Rust built-in test harness
- Mocking: mockall for trait dependencies
- Coverage: >90% for core business logic

**Integration Tests** [Source: architecture.md#test-strategy-and-standards]
- Location: `crates/artifact/tests/it_upload_artifact.rs`
- Test containers: MongoDB, MinIO, Kafka
- Framework: Custom Docker Compose orchestration

**Testing Standards** [Source: architecture.md#test-strategy-and-standards]
- AAA pattern (Arrange, Act, Assert)
- No inline tests - separate `_test.rs` files
- Test data factories for consistent test data
- Proper cleanup after tests

### Technical Constraints
**Performance** [Source: architecture.md#technical-considerations]
- Latency: <50ms for metadata operations (p99)
- Large file support: >100MB with streaming
- Memory efficiency: avoid excessive memory consumption

**Security** [Source: architecture.md#security]
- Input validation at API boundary
- Authentication via JWT tokens
- Authorization via Cedar ABAC policies
- No secrets in code - use environment variables
- HTTPS enforcement for all communications

**Error Handling** [Source: architecture.md#error-handling-strategy]
- Custom error types with thiserror crate
- Proper error propagation with ? operator
- Structured logging with tracing crate
- Correlation IDs for request tracing

## Testing

### Testing Standards from Architecture
**Test Organization** [Source: architecture.md#test-strategy-and-standards]
- Unit tests in separate `_test.rs` files co-located with source
- Integration tests in `tests/` directory
- No `#[cfg(test)]` modules in `src/` files

**Test Infrastructure** [Source: architecture.md#test-strategy-and-standards]
- MongoDB: testcontainers for ephemeral instances
- S3: testcontainers with MinIO
- Kafka: testcontainers for ephemeral instances
- External APIs: wiremock for HTTP stubbing

**Test Data Management** [Source: architecture.md#test-strategy-and-standards]
- Factories and builders for test data generation
- Proper cleanup after test execution
- Isolated test data to prevent interference

### Specific Testing Requirements for This Story
- Test multipart form parsing with various file types
- Test checksum validation with correct and incorrect hashes
- Test authentication failure scenarios
- Test authorization policy enforcement
- Test storage adapter error handling
- Test event publishing reliability
- Test large file upload performance
- Test concurrent upload scenarios

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-06 | 1.0 | Initial story draft | Scrum Master |

## Dev Agent Record

### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results
