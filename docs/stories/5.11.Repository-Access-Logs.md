# Story 5.11: Repository Access Logs

## Status
- Draft

## Story
**Como** un Oficial de Seguridad y Operaciones,
**quiero** tener un registro de auditoría detallado de todas las operaciones de acceso a los artefactos,
**para** poder realizar análisis forenses, depurar problemas de acceso y monitorizar la actividad del repositorio.

## Acceptance Criteria
1.  Cada petición de subida (upload) y descarga (download) de un artefacto debe generar una entrada de log.
2.  El registro de logs no debe impactar negativamente en la latencia de las peticiones; la generación del log debe ser asíncrona al ciclo de petición-respuesta.
3.  Cada entrada de log debe contener como mínimo: timestamp, IP de origen, principal (usuario/servicio), acción (`UPLOAD`/`DOWNLOAD`), repositorio, ruta del artefacto, y el código de estado de la respuesta (ej: 200, 404).
4.  Debe existir un endpoint en la API para consultar los logs de acceso, permitiendo filtrar al menos por repositorio, principal y rango de fechas.
5.  Los logs deben almacenarse en un sistema persistente y optimizado para búsquedas.

## Tasks / Subtasks
- [ ] Tarea 1: Definir el esquema del log y configurar la cola de mensajes. (AC: 3)
    - [ ] Subtarea 1.1: Definir una struct `AccessLogEntry` en Rust con todos los campos requeridos y serializable a JSON.
    - [ ] Subtarea 1.2: Configurar un topic en RabbitMQ (o un canal asíncrono de Tokio como primera aproximación) para recibir los eventos de log.
- [ ] Tarea 2: Implementar un `middleware` de logging en el framework web (ej: Axum/Actix). (AC: 1, 2)
    - [ ] Subtarea 2.1: Crear un middleware que se ejecute para cada petición a las rutas de artefactos.
    - [ ] Subtarea 2.2: El middleware debe capturar la información de la petición (IP, usuario, etc.) y, una vez que la respuesta se ha generado, capturar el código de estado.
    - [ ] Subtarea 2.3: El middleware debe instanciar la struct `AccessLogEntry`, serializarla y enviarla a la cola de mensajes de forma no bloqueante (`fire-and-forget`).
- [ ] Tarea 3: Desarrollar el servicio consumidor de logs (Log Ingestor). (AC: 5)
    - [ ] Subtarea 3.1: Crear un nuevo binario o servicio `log-ingestor` que actúe como consumidor de la cola de mensajes.
    - [ ] Subtarea 3.2: Implementar la lógica para consumir los logs en lotes (batches) para mayor eficiencia.
    - [ ] Subtarea 3.3: Configurar el cliente de Tantivy y definir el mapeo del índice (`index mapping`) para `access_logs`.
    - [ ] Subtarea 3.4: Implementar la lógica para escribir los lotes de logs en Tantivy.
- [ ] Tarea 4: Implementar la API de consulta de logs. (AC: 4)
    - [ ] Subtarea 4.1: Crear un endpoint `GET /api/v1/logs/access` que acepte parámetros de consulta para filtrar.
    - [ ] Subtarea 4.2: Implementar la lógica que construya una consulta de Tantivy a partir de los filtros de la API, incluyendo paginación y ordenación por fecha.
- [ ] Tarea 5: Pruebas de la pipeline completa.
    - [ ] Subtarea 5.1: Probar que una petición a la API genera correctamente un mensaje en la cola.
    - [ ] Subtarea 5.2: Probar que el `log-ingestor` consume el mensaje y lo escribe correctamente en Tantivy.
    - [ ] Subtarea 5.3: Probar que el endpoint de consulta de logs puede recuperar la entrada de log generada.

## Dev Notes

### Guía de Implementación y Contexto Arquitectónico

**Decisión Arquitectónica Clave: Pipeline de Ingesta de Logs Asíncrona**

Es **crítico** no escribir los logs directamente en la base de datos desde el servicio que maneja la petición del usuario. Hacerlo crearía un cuello de botella terrible. La arquitectura recomendada es la siguiente:

```text
[Cliente] -> [API Service] --(1)--> [Respuesta]
                 |
                 +----(2)----> [Cola de Mensajes (RabbitMQ)] --(3)--> [Log Ingestor Service] --(4)--> [Tantivy]