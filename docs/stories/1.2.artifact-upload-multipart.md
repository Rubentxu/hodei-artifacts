# Story 1.2: Subida de Artefactos Multi-parte

## Status

Implementación completada (Fase 1 + Fase 2: Reanudación y Progreso) - Todos los tests pasan

## Story

**As a** CI/CD System or Developer,
**I want** to upload large artifacts (>100MB) using multipart streaming,
**so that** the upload process is memory-efficient and resilient to network interruptions.

## Acceptance Criteria

1. The system must support multipart/form-data streaming for artifact uploads.
2. The upload process must not load the entire file into memory at once.
3. The system must be able to handle files larger than available RAM.
4. Checksums must be calculated on the fly as chunks are received.
5. The system should provide a mechanism to resume interrupted uploads (corresponds to feature E1.F08).
6. The API should gracefully handle network errors during the stream.
7. An `UploadProgressUpdated` event could be published periodically.
8. The final `ArtifactUploaded` event is only published after all parts are successfully received and assembled.

### Estado por Criterio

- [x] 1. Streaming multipart soportado en el endpoint (Axum, lectura por chunks)
- [x] 2. No se carga el archivo completo en memoria (buffer a fichero temporal)
- [x] 3. Soporte de ficheros mayores que la RAM (pipeline por chunks)
- [x] 4. Checksum SHA-256 en streaming (on-the-fly)
- [x] 5. Reanudación de uploads (E1.F08) completada
- [x] 6. Manejo robusto de errores de red/stream (respuestas 4xx/500)
- [x] 7. Publicación de eventos de progreso (E1.F06) completada
- [x] 8. Evento final publicado tras completar ensamblado/guardado

## Tasks / Subtasks

- [x] Enhance the Axum endpoint to handle multipart streams efficiently.
- [x] Implement chunk-by-chunk processing of the uploaded file.
- [x] Integrate streaming hash calculation (SHA-256).
- [x] Implement logic for temporary storage of parts for resumable uploads. (E1.F08)
- [x] Develop robust error handling for stream interruptions.
- [x] Write unit and integration tests for the multipart upload flow. (Makefile: test-artifact-unit, test-artifact-integration) - Todos los tests pasan
- [x] Test with very large files to ensure memory efficiency.
- [x] Implement progress event publishing (E1.F06).

## Dev Notes

### Implementación actual (Fase 1 + Fase 2)
- Handler Axum procesa multipart en streaming, escribiendo a archivo temporal mientras calcula SHA-256.
- Caso de uso admite subida desde fichero temporal (memoria constante) vía `execute_from_temp_file`.
- Adaptadores de almacenamiento: S3/MinIO y filesystem local; ambos soportan `upload_from_path` (streaming real).
- Implementación de funcionalidad completada y todos los tests unitarios e integración pasan (Makefile: `make test-artifact-unit`, `make test-artifact-integration`).
- Reanudación (E1.F08) implementada con `ChunkedUploadStorage` para FS local y S3.
- Progreso (E1.F06) implementado con publicación de eventos `UploadProgressUpdated` durante la subida.

### Data Models
- No new data models. This story enhances the existing `Artifact` and `PhysicalArtifact` lifecycle.

### API Specifications
- **Endpoint**: `POST /artifacts` (enhanced)
- El endpoint procesa el `file` del multipart como stream.
- Para reanudación: headers `Upload-ID`, `Chunk-Number`, `Chunks-Total`.

### Technical Constraints
- **Memory Usage**: Must remain low and constant regardless of file size.
- **Performance**: Streaming should be implemented with minimal overhead.

---

## Detalles de implementación (importante)

- Handler HTTP (Axum):
  - Archivo: `crates/artifact/src/features/upload_artifact/api.rs`.
  - Lee `file` como stream (`field.chunk()`), escribe a `tempfile` con `tokio::fs::File` y calcula SHA-256 on-the-fly (`sha2::Sha256::update`).
  - Valida checksum si se envía; mapea errores de stream a 400 y fallos internos a 500.
  - Logs y spans con `tracing`: incluye `upload_artifact_execution`, `file_name`, `content_length`.
  - Soporta headers para reanudación: `Upload-ID`, `Chunk-Number`, `Chunks-Total`.

- Caso de uso:
  - Archivo: `crates/artifact/src/features/upload_artifact/use_case.rs`.
  - Método `execute_from_temp_file` deduplica por hash, sube contenido y publica `PackageVersionPublished`.
  - Nuevo método `execute_from_stream` para manejar subidas por chunks con progreso.

- Puertos (Hexagonal):
  - Archivo: `crates/artifact/src/features/upload_artifact/ports.rs`.
  - `ArtifactStorage` extendido con `upload_from_path(&Path, hash)` (por defecto delega a `upload`).
  - `ChunkedUploadStorage` (trait) implementado para reanudación (guardar/recuperar/ensamblar/limpiar chunks).

- Adaptadores (Infra):
  - Archivo: `crates/artifact/src/features/upload_artifact/adapter.rs`.
  - `S3ArtifactStorage` (MinIO/S3) soporta `upload_from_path` vía `ByteStream::from_path`.
  - `LocalFsArtifactStorage` guarda en filesystem (`rename` con fallback a `copy`).
  - Implementación de `ChunkedUploadStorage` para ambos adaptadores (S3 y local).
  - `MongoDbRepository` y `RabbitMqEventPublisher` activos; evento final tras persistencia.

- Seguridad / Auth:
  - Middleware simple en `api.rs`: exige `Authorization: Bearer` salvo bypass de test o `HODEI_AUTH_DISABLED=true`.

- Observabilidad:
  - `tracing` en endpoint y caso de uso: INFO/DEBUG/ERROR; tests assertan logs y spans.

## Curiosidades y Decisiones de Diseño

- **Streaming a Fichero Temporal**: La solución implementada para el streaming es un pipeline pragmático: `HTTP Stream -> Temp File -> Storage Stream`. El handler de Axum consume el stream de la petición y lo escribe directamente a un fichero temporal en disco, mientras calcula el hash SHA256 en tiempo real. Una vez el fichero temporal está completo, se pasa la ruta de este fichero al caso de uso. Este enfoque garantiza un **uso de memoria RAM constante y mínimo** (criterio clave), sin importar el tamaño del artefacto, y desacopla la complejidad del streaming de la lógica de negocio principal.

- **Separación de Casos de Uso (Chunks vs. Fichero Completo)**: Se ha introducido un nuevo `UploadArtifactChunkUseCase` y el trait `ChunkedUploadStorage` para manejar la lógica de subidas por partes de forma aislada. Esta separación permite manejar la **reanudación de subidas (E1.F08)** de manera eficiente. Permite que la lógica de gestionar chunks (guardado, reensamblado) evolucione de forma independiente a la lógica de procesar un artefacto ya completo, siguiendo el Principio de Responsabilidad Única.

- **Idempotencia en el Almacenamiento**: El adaptador `LocalFsArtifactStorage` intenta primero un `rename` del fichero temporal al destino final, que es una operación atómica en la mayoría de sistemas de ficheros. Si falla (ej. por estar en diferentes dispositivos), recurre a un `copy`, asegurando que la operación se complete de forma robusta.

- **Progreso de Subida**: Se implementa publicación de eventos `UploadProgressUpdated` durante la subida de archivos grandes, permitiendo a los clientes seguir el progreso de la operación. Los eventos se publican periódicamente durante la subida para evitar saturar el bus de eventos.

## Evidencias (tests y ejecución)

- Comandos de Makefile:
  - Unitarios: `make test-artifact-unit` → Todos los tests PASAN.
  - Integración: `make test-artifact-integration` → Todos los tests PASAN.
- Cobertura de criterios:
  - 1,2,3,4,5,6,7,8 todos verificados por tests unitarios e integración.
- Archivos de test relevantes:
  - Unit: `crates/artifact/src/features/upload_artifact/api_test.rs`, `use_case_test.rs`, `use_case_chunks_test.rs`.
  - Integración: `crates/artifact/tests/it_upload_artifact.rs` (+ helpers/compose).

## Relaciones y trazabilidad

- PRD / Épicas:
  - Relacionado con E1.F02 (esta historia), depende de E1.F01 (core) y se extiende con E1.F08 (reanudación) y E1.F06 (progreso).
  - PRD doc: `docs/prd/2-epicas-principales-enriquecidas-core-business-value.md`.

- Arquitectura:
  - Alineado con Monolito Modular + VSA + Hexagonal (Ports/Adapters); ver `docs/architecture.md`.
  - Almacenamiento binario: S3-compatible (MinIO) o FS local; adaptadores desacoplados vía `ArtifactStorage`.

- Testing y organización:
  - Cumple `docs/testing-organization.md`: tests unitarios en archivos separados, integración con `testcontainers`, asserts de logs con `tracing`.

- Próximas integraciones (plan):
  - Evaluar `object_store` como backend unificado (S3/FS) para multipart y reintentos.

