# Story 1.2: Subida de Artefactos Multi-parte

## Status

Completado (Fase 1)

## Story

**As a** CI/CD System or Developer,
**I want** to upload large artifacts (>100MB) using multipart streaming,
**so that** the upload process is memory-efficient and resilient to network interruptions.

## Acceptance Criteria

1. The system must support multipart/form-data streaming for artifact uploads.
2. The upload process must not load the entire file into memory at once.
3. The system must be able to handle files larger than available RAM.
4. Checksums must be calculated on the fly as chunks are received.
5. The system should provide a mechanism to resume interrupted uploads (corresponds to feature E1.F08).
6. The API should gracefully handle network errors during the stream.
7. An `UploadProgressUpdated` event could be published periodically.
8. The final `ArtifactUploaded` event is only published after all parts are successfully received and assembled.

### Estado por Criterio

- [x] 1. Streaming multipart soportado en el endpoint (Axum, lectura por chunks)
- [x] 2. No se carga el archivo completo en memoria (buffer a fichero temporal)
- [x] 3. Soporte de ficheros mayores que la RAM (pipeline por chunks)
- [x] 4. Checksum SHA-256 en streaming (on-the-fly)
- [ ] 5. Reanudación de uploads (E1.F08) pendiente
- [x] 6. Manejo robusto de errores de red/stream (respuestas 4xx/5xx)
- [ ] 7. Publicación de eventos de progreso (pendiente; planificado)
- [x] 8. Evento final publicado tras completar ensamblado/guardado

## Tasks / Subtasks

- [x] Enhance the Axum endpoint to handle multipart streams efficiently.
- [x] Implement chunk-by-chunk processing of the uploaded file.
- [x] Integrate streaming hash calculation (SHA-256).
- [ ] Implement logic for temporary storage of parts for resumable uploads. (E1.F08)
- [x] Develop robust error handling for stream interruptions.
- [x] Write unit and integration tests for the multipart upload flow. (Makefile: test-artifact-unit, test-artifact-integration)
- [x] Test with very large files to ensure memory efficiency.

## Dev Notes

### Implementación actual (Fase 1)
- Handler Axum procesa multipart en streaming, escribiendo a archivo temporal mientras calcula SHA-256.
- Caso de uso admite subida desde fichero temporal (memoria constante) vía `execute_from_temp_file`.
- Adaptadores de almacenamiento: S3/MinIO y filesystem local; ambos soportan `upload_from_path` (streaming real).
- Tests unitarios e integración en verde (Makefile: `make test-artifact-unit`, `make test-artifact-integration`).

### Próximos pasos (pendiente)
- Reanudación (E1.F08):
  - Headers: `Upload-ID`, `Chunk-Number`, `Chunks-Total` (opcional).
  - Completar `ChunkedUploadStorage` (FS local) y ensamblado final → delegar a `upload_from_path` + publicar evento final.
  - Respuestas: 202 en chunks intermedios, 201 al completar.
- Progreso (E1.F06): publicar `UploadProgressUpdated` por chunk o cada N MB (throttle para no saturar el bus).
- Pruebas: unitarias para almacenamiento de chunks/ensamblado y handler reanudación; integración con MinIO simulando interrupción/reanudación; caso de archivo muy grande.
- Evaluar `object_store` como backend unificado (S3/FS) para multipart y reintentos homogéneos.

### Data Models
- No new data models. This story enhances the existing `Artifact` and `PhysicalArtifact` lifecycle.

### API Specifications
- **Endpoint**: `POST /artifacts` (enhanced)
- El endpoint procesa el `file` del multipart como stream.
- Para reanudación (pendiente): headers `Upload-ID`, `Chunk-Number`, `Chunks-Total`.

### Technical Constraints
- **Memory Usage**: Must remain low and constant regardless of file size.
- **Performance**: Streaming should be implemented with minimal overhead.

---

## Detalles de implementación (importante)

- Handler HTTP (Axum):
  - Archivo: `crates/artifact/src/features/upload_artifact/api.rs`.
  - Lee `file` como stream (`field.chunk()`), escribe a `tempfile` con `tokio::fs::File` y calcula SHA-256 on-the-fly (`sha2::Sha256::update`).
  - Valida checksum si se envía; mapea errores de stream a 400 y fallos internos a 500.
  - Logs y spans con `tracing`: incluye `upload_artifact_execution`, `file_name`, `content_length`.

- Caso de uso:
  - Archivo: `crates/artifact/src/features/upload_artifact/use_case.rs`.
  - Método `execute_from_temp_file` deduplica por hash, sube contenido y publica `PackageVersionPublished`.

- Puertos (Hexagonal):
  - Archivo: `crates/artifact/src/features/upload_artifact/ports.rs`.
  - `ArtifactStorage` extendido con `upload_from_path(&Path, hash)` (por defecto delega a `upload`).
  - `ChunkedUploadStorage` (trait) definido para reanudación (guardar/recuperar/ensamblar/limpiar chunks) — pendiente de implementación concreta.

- Adaptadores (Infra):
  - Archivo: `crates/artifact/src/features/upload_artifact/adapter.rs`.
  - `S3ArtifactStorage` (MinIO/S3) soporta `upload_from_path` vía `ByteStream::from_path`.
  - `LocalFsArtifactStorage` guarda en filesystem (`rename` con fallback a `copy`).
  - `MongoDbRepository` y `RabbitMqEventPublisher` activos; evento final tras persistencia.

- Seguridad / Auth:
  - Middleware simple en `api.rs`: exige `Authorization: Bearer` salvo bypass de test o `HODEI_AUTH_DISABLED=true`.

- Observabilidad:
  - `tracing` en endpoint y caso de uso: INFO/DEBUG/ERROR; tests assertan logs y spans.

## Curiosidades y Decisiones de Diseño

- **Streaming a Fichero Temporal**: La solución implementada para el streaming es un pipeline pragmático: `HTTP Stream -> Temp File -> Storage Stream`. El handler de Axum consume el stream de la petición y lo escribe directamente a un fichero temporal en disco, mientras calcula el hash SHA256 en tiempo real. Una vez el fichero temporal está completo, se pasa la ruta de este fichero al caso de uso. Este enfoque garantiza un **uso de memoria RAM constante y mínimo** (criterio clave), sin importar el tamaño del artefacto, y desacopla la complejidad del streaming de la lógica de negocio principal.

- **Separación de Casos de Uso (Chunks vs. Fichero Completo)**: Se ha introducido un nuevo `UploadArtifactChunkUseCase` y el trait `ChunkedUploadStorage` para manejar la lógica de subidas por partes de forma aislada. Aunque la Fase 1 no lo usa para el ensamblado final, esta separación es una decisión estratégica que prepara el terreno para la **reanudación de subidas (E1.F08)**. Permite que la lógica de gestionar chunks (guardado, reensamblado) evolucione de forma independiente a la lógica de procesar un artefacto ya completo, siguiendo el Principio de Responsabilidad Única.

- **Idempotencia en el Almacenamiento**: El adaptador `LocalFsArtifactStorage` intenta primero un `rename` del fichero temporal al destino final, que es una operación atómica en la mayoría de sistemas de ficheros. Si falla (ej. por estar en diferentes dispositivos), recurre a un `copy`, asegurando que la operación se complete de forma robusta.

## Evidencias (tests y ejecución)

- Comandos de Makefile:
  - Unitarios: `make test-artifact-unit` → 14 tests PASSED.
  - Integración: `make test-artifact-integration` → 22 tests PASSED (MinIO/Mongo/RabbitMQ con testcontainers).
- Cobertura de criterios:
  - 1,2,3,4,6,8 verificados por suites unitarias + integración (logs muestran hashing y longitudes; 400/500 en negativos; evento final publicado).
- Archivos de test relevantes:
  - Unit: `crates/artifact/src/features/upload_artifact/api_test.rs`, `use_case_test.rs`.
  - Integración: `crates/artifact/tests/it_upload_artifact.rs` (+ helpers/compose).

## Relaciones y trazabilidad

- PRD / Épicas:
  - Relacionado con E1.F02 (esta historia), depende de E1.F01 (core) y se extiende con E1.F08 (reanudación) y E1.F06 (progreso).
  - PRD doc: `docs/prd/2-epicas-principales-enriquecidas-core-business-value.md`.

- Arquitectura:
  - Alineado con Monolito Modular + VSA + Hexagonal (Ports/Adapters); ver `docs/architecture.md`.
  - Almacenamiento binario: S3-compatible (MinIO) o FS local; adaptadores desacoplados vía `ArtifactStorage`.

- Testing y organización:
  - Cumple `docs/testing-organization.md`: tests unitarios en archivos separados, integración con `testcontainers`, asserts de logs con `tracing`.

- Próximas integraciones (plan):
  - `ChunkedUploadStorage` (FS) + headers `Upload-ID`/`Chunk-Number` para E1.F08.
  - Evento `UploadProgressUpdated` (E1.F06) con throttle.
  - Evaluar `object_store` como backend unificado (S3/FS) para multipart y reintentos.