# Historia 4.25: Policy Machine Learning Optimization

## Estado
- **Borrador (Draft)**

## Historia
**Como** sistema de autorización inteligente,
**quiero** utilizar Machine Learning para analizar y optimizar las políticas de acceso existentes,
**para que** pueda sugerir mejoras, simplificar reglas complejas y adaptarme a los patrones de acceso cambiantes.

## Criterios de Aceptación
1.  Se ha implementado un `PolicyOptimizationEngine` que puede analizar datos de rendimiento de políticas del `AuditTrail`.
2.  Se ha definido una interfaz (trait) `PolicyMLModel` que desacopla el motor de la implementación específica del modelo de ML.
3.  Se ha implementado un sistema de recolección de feedback para recopilar datos sobre la efectividad de las políticas (p. ej., a partir de los flujos de solicitud de acceso).
4.  El motor puede generar un informe con sugerencias de optimización, como la simplificación de condiciones o la fusión de políticas similares.
5.  Existe un endpoint de API que inicia el proceso de análisis y devuelve las recomendaciones generadas.
6.  Se publica un evento `PolicyRecommendationGenerated` cuando se generan nuevas sugerencias de optimización.

## Tareas / Subtareas
- [ ] **Tarea 1: Implementar el Motor de Optimización** (AC: #1)
    - [ ] Crear la estructura `PolicyOptimizationEngine` siguiendo el patrón de la investigación técnica.
- [ ] **Tarea 2: Definir la Interfaz del Modelo de ML** (AC: #2)
    - [ ] Definir el trait `PolicyMLModel` con un método `generate_optimizations`.
    - [ ] Crear una implementación inicial simulada (`MockPolicyMLModel`) que devuelva sugerencias basadas en reglas heurísticas simples (p. ej., "política no utilizada en los últimos 90 días").
- [ ] **Tarea 3: Implementar el Bucle de Feedback** (AC: #3)
    - [ ] Crear un `FeedbackCollector` que pueda agregar datos del `AuditTrail` y del `AccessRequestRepository` para medir el rendimiento y la fricción de las políticas.
- [ ] **Tarea 4: Implementar la Lógica de Análisis y Sugerencia** (AC: #4)
    - [ ] Implementar el método principal en el `PolicyOptimizationEngine` que utiliza el colector de feedback y el modelo de ML para generar un `OptimizationReport`.
- [ ] **Tarea 5: Implementar el Endpoint de la API** (AC: #5)
    - [ ] Añadir e implementar el endpoint `POST /api/v1/policies/optimize`.
- [ ] **Tarea 6: Publicar Evento de Dominio** (AC: #6)
    - [ ] Integrar la publicación del evento `PolicyRecommendationGenerated` en el motor.
- [ ] **Tarea 7: Añadir Pruebas**
    - [ ] Escribir pruebas unitarias para el `PolicyOptimizationEngine` utilizando el modelo simulado.

## Notas para el Desarrollador
Esta historia establece la infraestructura para una capacidad de ML muy avanzada. El enfoque inicial no debe ser construir un modelo de ML complejo, sino crear la arquitectura que lo soporte.

### Patrón de Implementación
* La implementación debe seguir el patrón **"ML-Driven Policy Tuning"** de la investigación técnica. La clave es la separación de responsabilidades entre el motor, el modelo y el colector de datos.
    ```rust
    // Pseudocódigo de referencia para el motor de optimización
    // Fuente: Investigación Técnica de la Épica E4
    struct PolicyOptimizationEngine {
        policy_repository: Arc<dyn PolicyRepository>,
        ml_model: Arc<dyn PolicyMLModel>,
        feedback_loop: FeedbackCollector,
    }

    impl PolicyOptimizationEngine {
        async fn optimize_policies(&self) -> Result<OptimizationReport> {
            // 1. Recolectar datos de rendimiento y feedback
            // 2. Para políticas de bajo rendimiento, pedir sugerencias al modelo de ML
            // 3. Generar un informe con las sugerencias
        }
    }
    ```
### Modelo Simulado (Mock)
* Para esta historia, el `PolicyMLModel` puede ser una implementación simple basada en reglas (heurísticas) en lugar de un modelo de ML real. Por ejemplo, puede sugerir eliminar políticas que no se han utilizado en mucho tiempo o fusionar políticas que son sintácticamente muy similares. Esto permite construir y probar todo el pipeline sin depender de un equipo de ciencia de datos.